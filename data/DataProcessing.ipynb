{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "O6nqqosKIRBs",
        "qjjE6aQtKbS6",
        "gbaWprE1KwD8",
        "bEwkkkfiK0wP",
        "ooptjvmgD-B_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcAEZFABFVK2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/MedicalData/\"\n",
        "\n",
        "# EHRs\n",
        "med_file = path + \"MIMIC-IV/prescriptions_ndc.csv\"\n",
        "diag_file = path + \"MIMIC-IV/diagnoses_icd.csv\"\n",
        "proc_file = path + \"MIMIC-IV/procedures_icd.csv\"\n",
        "patients_file = path + \"MIMIC-IV/patients.csv\"\n",
        "\n",
        "diag_hadm_file = path + \"MIMIC-IV/hadm_diagnoses.csv\"\n",
        "med_hadm_file = path + \"MIMIC-IV/hadm_prescriptions.csv\"\n",
        "\n",
        "adm_hadm_file = path + \"hadm_code.csv\"\n",
        "\n",
        "ddi_file = path + \"drug-DDI.csv\"\n",
        "\n",
        "# ICD Codes\n",
        "diag_icd_file = path + \"MIMIC-IV/d_icd_diagnoses.csv\"\n",
        "proc_icd_file = path + \"MIMIC-IV/d_icd_procedures.csv\"\n",
        "\n",
        "# Mappings\n",
        "ndc2atc_file = path + \"Mappings/ndc2atc_level4.csv\"\n",
        "ndc2rxnorm_file = path + \"Mappings/ndc2rxnorm_mapping.txt\"\n",
        "cid2atc_file = path + \"Mappings/drug-atc-processed.csv\"\n",
        "drugmap_file = path + \"Mappings/drug_codes_mapping.csv\"\n",
        "drugmap_atc_file = path + \"Mappings/drug_codes_mapping_atc.csv\"\n",
        "atc4to3_file = path + \"Mappings/atc4to3_map.csv\""
      ],
      "metadata": {
        "id": "ow32J8ed8Upm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prescriptions**"
      ],
      "metadata": {
        "id": "O6nqqosKIRBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_med():\n",
        "    # process prescription dataset\n",
        "    med_pd = pd.read_csv(med_file, dtype={'ndc':'category'})\n",
        "    med_pd.drop(index = med_pd[med_pd['ndc'] == '0'].index, axis=0, inplace=True)\n",
        "    med_pd.fillna(method='pad', inplace=True)\n",
        "    med_pd.dropna(inplace=True)\n",
        "    med_pd.drop_duplicates(inplace=True)\n",
        "    med_pd = med_pd.reset_index(drop=True)\n",
        "\n",
        "    # change subject_id to serial numbers\n",
        "    hadm_code_pd = pd.read_csv(path + 'hadm_code.csv')\n",
        "    med_pd = med_pd.merge(hadm_code_pd, how='left', on='hadm_id')\n",
        "\n",
        "    # convert ndc medical data in prescriptions to atc5 format\n",
        "    def ndc2atc5(med_pd):\n",
        "        drugmap_pd = pd.read_csv(drugmap_atc_file, dtype={'ndc': 'category'})\n",
        "        drugmap_pd.drop(columns=['ndc10', 'rxcui', 'atc4', 'atc4_name', 'in_name', 'atc5', 'atc3'], inplace=True)\n",
        "\n",
        "        med_pd = med_pd.merge(drugmap_pd, how='left', on='ndc')\n",
        "\n",
        "        med_pd.dropna(inplace=True)\n",
        "        med_pd.drop_duplicates(subset=[\"hadm_id\", \"ndc\"], keep=\"first\", inplace=True)\n",
        "        med_pd.drop_duplicates(subset=[\"hadm_id\", \"atc_idx\"], keep=\"first\", inplace=True)\n",
        "        med_pd = med_pd.reset_index(drop=True)\n",
        "\n",
        "        return med_pd\n",
        "\n",
        "    med_pd = ndc2atc5(med_pd)\n",
        "\n",
        "    med_pd_atc3 = med_pd.drop(columns=['subject_id', 'hadm_id', 'ndc', 'ndc_idx', 'atc_idx'])\n",
        "    med_pd_atc3.drop_duplicates(subset=['hadm_code', 'atc3_idx'], inplace=True)\n",
        "    med_pd_atc3.reset_index(drop=True, inplace=True)\n",
        "    med_pd_atc3.rename(columns = {'atc3_idx':'atc_idx'}, inplace = True)\n",
        "\n",
        "    med_pd.drop(columns=['subject_id', 'hadm_id', 'ndc', 'ndc_idx', 'atc3_idx'], inplace=True)\n",
        "\n",
        "    med_pd = med_pd.astype(int)\n",
        "    med_pd_atc3 = med_pd_atc3.astype(int)\n",
        "\n",
        "    med_pd.to_csv(path + 'Triplets/med_triplets.csv', index=None)\n",
        "    med_pd_atc3.to_csv(path + 'Triplets/med_triplets_atc3.csv', index=None)\n",
        "\n",
        "    return med_pd, med_pd_atc3\n",
        "\n",
        "med_pd, med_pd_atc3 = process_med()"
      ],
      "metadata": {
        "id": "iSl4S8R0a133"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Diagnoses**"
      ],
      "metadata": {
        "id": "qjjE6aQtKbS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# process icd diagnoses codes for encoding\n",
        "# run only once preferably\n",
        "diag_icd_pd = pd.read_csv(diag_icd_file)\n",
        "diag_icd_pd.fillna(method='pad', inplace=True)\n",
        "diag_icd_pd.dropna(inplace=True)\n",
        "diag_icd_pd.drop_duplicates(inplace=True)\n",
        "\n",
        "diag_icd_pd['icd'] = diag_icd_pd['icd_version'].astype(str) + \"-\" + diag_icd_pd['icd_code']\n",
        "diag_icd_pd['icd_idx'] = range(len(diag_icd_pd))\n",
        "\n",
        "diag_icd_pd.to_csv(path+'icd_diag_codes.csv', index=None)"
      ],
      "metadata": {
        "id": "1ew7qzMlBNYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_diag():\n",
        "    # process diagnoses dataset\n",
        "    diag_pd = pd.read_csv(diag_file, dtype={'icd_version': 'category'})\n",
        "    diag_pd.fillna(method='pad', inplace=True)\n",
        "    diag_pd.dropna(inplace=True)\n",
        "    diag_pd.drop_duplicates(inplace=True)\n",
        "    diag_pd.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # change subject_id to serial numbers\n",
        "    hadm_code_pd = pd.read_csv(path+'hadm_code.csv')\n",
        "    diag_pd = diag_pd.merge(hadm_code_pd, how='left', on='hadm_id')\n",
        "\n",
        "    diag_pd['icd'] = diag_pd['icd_version'].astype(str) + \"-\" + diag_pd['icd_code']\n",
        "\n",
        "    diag_icd_pd = pd.read_csv(path+'icd_diag_codes.csv')\n",
        "    diag_icd_pd.drop(columns=['icd_code', 'icd_version', 'long_title'], inplace=True)\n",
        "\n",
        "    diag_pd = diag_pd.merge(diag_icd_pd, how='left', on='icd')\n",
        "\n",
        "    diag_pd.drop(columns=['hadm_id', 'subject_id', 'seq_num', 'icd_code', 'icd_version', 'icd'], inplace=True)\n",
        "    diag_pd.dropna(inplace=True)\n",
        "    diag_pd.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    diag_pd = diag_pd.astype(int)\n",
        "\n",
        "    diag_pd.to_csv(path+'Triplets/diag_triplets.csv', index=None)\n",
        "\n",
        "    return diag_pd\n",
        "\n",
        "diag_pd = process_diag()"
      ],
      "metadata": {
        "id": "JK-pA2ozckrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Procedures**"
      ],
      "metadata": {
        "id": "gbaWprE1KwD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# process icd procedure codes for encoding\n",
        "# run only once preferably\n",
        "proc_icd_pd = pd.read_csv(proc_icd_file)\n",
        "proc_icd_pd.fillna(method='pad', inplace=True)\n",
        "proc_icd_pd.dropna(inplace=True)\n",
        "proc_icd_pd.drop_duplicates(inplace=True)\n",
        "\n",
        "proc_icd_pd['icd'] = proc_icd_pd['icd_version'].astype(str) + \"-\" + proc_icd_pd['icd_code']\n",
        "proc_icd_pd['icd_idx'] = range(len(proc_icd_pd))\n",
        "\n",
        "proc_icd_pd.to_csv(path + 'icd_proc_codes.csv', index=None)"
      ],
      "metadata": {
        "id": "2Je1wuDCDwfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_proc():\n",
        "    # process procedures dataset\n",
        "    proc_pd = pd.read_csv(proc_file, dtype={'icd_version': 'category'})\n",
        "    proc_pd.fillna(method='pad', inplace=True)\n",
        "    proc_pd.dropna(inplace=True)\n",
        "    proc_pd.drop_duplicates(inplace=True)\n",
        "    proc_pd.reset_index(drop=True, inplace=True)\n",
        "    proc_pd.sort_values(by=['hadm_id'], inplace=True)\n",
        "\n",
        "    # change subject_id to serial numbers\n",
        "    hadm_code_pd = pd.read_csv(path+'hadm_code.csv')\n",
        "    hadm_code_pd.drop(columns=[\"subject_id\"], inplace=True)\n",
        "    proc_pd = proc_pd.merge(hadm_code_pd, how='left', on='hadm_id')\n",
        "\n",
        "    proc_pd['icd'] = proc_pd['icd_version'].astype(str) + \"-\" + proc_pd['icd_code']\n",
        "\n",
        "    proc_icd_pd = pd.read_csv(path+'icd_proc_codes.csv')\n",
        "    proc_icd_pd.drop(columns=['icd_code', 'icd_version', 'long_title'], inplace=True)\n",
        "\n",
        "    proc_pd = proc_pd.merge(proc_icd_pd, how='left', on='icd')\n",
        "\n",
        "    proc_pd.drop(columns=['hadm_id', 'seq_num', 'icd_code', 'icd_version', 'icd'], inplace=True)\n",
        "    proc_pd.dropna(inplace=True)\n",
        "    proc_pd.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    proc_pd = proc_pd.astype(int)\n",
        "\n",
        "    proc_pd.to_csv(path+'Triplets/proc_triplets.csv', index=None)\n",
        "\n",
        "    return proc_pd\n",
        "\n",
        "proc_pd = process_proc()"
      ],
      "metadata": {
        "id": "sIqOU17BpWbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Drug-Drug Interactions**"
      ],
      "metadata": {
        "id": "bEwkkkfiK0wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drugmap_pd = pd.read_csv(drugmap_atc_file, dtype={'ndc': 'category'})\n",
        "atc5to3_map = drugmap_pd[['atc5', 'atc_idx', 'atc3', 'atc3_idx']].drop_duplicates().reset_index(drop=True)\n",
        "# atc5to3_map.to_csv(path+\"Mappings/atc5to3_map.csv\", index=False)"
      ],
      "metadata": {
        "id": "gtYL5VrTncMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_ddi():\n",
        "  ddi_pd = pd.read_csv(ddi_file)\n",
        "\n",
        "  ddi_most_pd = ddi_pd.groupby(by=['Polypharmacy Side Effect', 'Side Effect Name']).size().reset_index().rename(columns={0:'count'}).sort_values(by=['count'],ascending=False).reset_index(drop=True)\n",
        "  ddi_most_pd = ddi_most_pd.iloc[-40:,:]\n",
        "\n",
        "  filter_ddi_pd = ddi_pd.merge(ddi_most_pd[['Side Effect Name']], how='inner', on=['Side Effect Name'])\n",
        "  ddi_pd = filter_ddi_pd.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "  cid2atc_pd = pd.read_csv(cid2atc_file)\n",
        "  cid2atc_pd.drop(columns=[\"atc5\"], inplace=True)\n",
        "\n",
        "  ddi_pd = pd.merge(ddi_pd, cid2atc_pd, left_on='STITCH 1', right_on=\"STITCH\", how='left')\n",
        "  ddi_pd.rename(columns = {'atc_idx':'atc_idx-1'}, inplace = True)\n",
        "\n",
        "  ddi_pd = pd.merge(ddi_pd, cid2atc_pd, left_on='STITCH 2', right_on=\"STITCH\", how='left')\n",
        "  ddi_pd.rename(columns = {'atc_idx':'atc_idx-2'}, inplace = True)\n",
        "\n",
        "  ddi_pd.drop(columns=[\"STITCH 1\", \"STITCH 2\", \"STITCH_x\", \"STITCH_y\"], inplace=True)\n",
        "\n",
        "  ddi_pd.dropna(inplace=True)\n",
        "  ddi_pd.drop_duplicates(inplace=True)\n",
        "  ddi_pd = ddi_pd.reset_index(drop=True)\n",
        "\n",
        "  ddi_pd = ddi_pd.astype({\"atc_idx-1\": int, \"atc_idx-2\": int})\n",
        "\n",
        "  ddi_pd_atc3 = ddi_pd\n",
        "\n",
        "  ddi_pd_atc3 = pd.merge(ddi_pd_atc3, atc5to3_map, left_on='atc_idx-1', right_on=\"atc_idx\", how='left')\n",
        "  ddi_pd_atc3.drop(columns=[\"atc_idx-1\", \"atc_idx\", \"atc5\", \"atc3\"], inplace=True)\n",
        "  ddi_pd_atc3.rename(columns = {'atc3_idx':'atc_idx-1'}, inplace = True)\n",
        "\n",
        "  ddi_pd_atc3 = pd.merge(ddi_pd_atc3, atc5to3_map, left_on='atc_idx-2', right_on=\"atc_idx\", how='left')\n",
        "  ddi_pd_atc3.drop(columns=[\"atc_idx-2\", \"atc_idx\", \"atc5\", \"atc3\"], inplace=True)\n",
        "  ddi_pd_atc3.rename(columns = {'atc3_idx':'atc_idx-2'}, inplace = True)\n",
        "\n",
        "  ddi_pd_atc3.drop_duplicates(inplace=True)\n",
        "  ddi_pd_atc3.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  ddi_pd.to_csv(path+\"ddi_info.csv\", index=None)\n",
        "  ddi_pd_atc3.to_csv(path+\"ddi_info_atc3.csv\", index=None)\n",
        "\n",
        "  ddi_triplets_pd = ddi_pd[[\"atc_idx-1\", \"atc_idx-2\"]]\n",
        "  ddi_triplets_pd.to_csv(path+\"Triplets/ddi_triplets.csv\", index=None)\n",
        "\n",
        "  ddi_triplets_atc3_pd = ddi_pd_atc3[[\"atc_idx-1\", \"atc_idx-2\"]]\n",
        "  ddi_triplets_pd.to_csv(path+\"Triplets/ddi_triplets_atc3.csv\", index=None)\n",
        "\n",
        "  return ddi_pd, ddi_pd_atc3\n",
        "\n",
        "ddi_pd, ddi_pd_atc3 = process_ddi()"
      ],
      "metadata": {
        "id": "G2D70tV6coNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **EHRs**"
      ],
      "metadata": {
        "id": "y7V_JXLRglN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subj_hadm_pd = pd.read_csv(adm_hadm_file)\n",
        "subj_unique = subj_hadm_pd['subject_id'].unique()\n",
        "subj_unique = np.sort(subj_unique)\n",
        "subj_unique_range = range(len(subj_unique))\n",
        "subj_unique_pd = pd.DataFrame(subj_unique, columns=['subject_id'])\n",
        "subj_unique_pd['subject_code'] = subj_unique_range\n",
        "subj_hadm_pd = subj_hadm_pd.merge(subj_unique_pd, on=\"subject_id\", how=\"left\")"
      ],
      "metadata": {
        "id": "x5djfOpbhTLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hadm_unique = list(subj_hadm_pd['hadm_code'])\n",
        "\n",
        "med_pd_group = med_pd.groupby('hadm_code')\n",
        "med_pd_atc3_group = med_pd_atc3.groupby('hadm_code')\n",
        "diag_pd_group = diag_pd.groupby('hadm_code')\n",
        "proc_pd_group = proc_pd.groupby('hadm_code')\n",
        "\n",
        "ehr_dict = {\n",
        "    \"subject_code\": [],\n",
        "    \"hadm_code\": [],\n",
        "    \"med_codes\": [],\n",
        "    \"med_codes_atc3\": [],\n",
        "    \"diag_codes\": [],\n",
        "    \"proc_codes\": []\n",
        "}\n",
        "\n",
        "for hadm_code in hadm_unique:\n",
        "  ehr_dict[\"hadm_code\"].append(hadm_code)\n",
        "  ehr_dict[\"subject_code\"].append(subj_hadm_pd.loc[subj_hadm_pd['hadm_code'] == hadm_code]['subject_code'].item())\n",
        "\n",
        "  try:\n",
        "    ehr_dict[\"med_codes\"].append(list(med_pd_group.get_group(hadm_code)['atc_idx'].unique()))\n",
        "  except: ehr_dict[\"med_codes\"].append(None)\n",
        "\n",
        "  try:\n",
        "    ehr_dict[\"med_codes_atc3\"].append(list(med_pd_atc3_group.get_group(hadm_code)['atc_idx'].unique()))\n",
        "  except: ehr_dict[\"med_codes_atc3\"].append(None)\n",
        "\n",
        "  try:\n",
        "    ehr_dict[\"diag_codes\"].append(list(diag_pd_group.get_group(hadm_code)['icd_idx'].unique()))\n",
        "  except: ehr_dict[\"diag_codes\"].append(None)\n",
        "\n",
        "  try:\n",
        "    ehr_dict[\"proc_codes\"].append(list(proc_pd_group.get_group(hadm_code)['icd_idx'].unique()))\n",
        "  except: ehr_dict[\"proc_codes\"].append(None)"
      ],
      "metadata": {
        "id": "H1Fiwibi24do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ehr_pd = pd.DataFrame(ehr_dict)"
      ],
      "metadata": {
        "id": "0ZfuMuLUoNxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records = []\n",
        "records_atc3 = []\n",
        "\n",
        "i = 0\n",
        "for id in np.sort(ehr_pd['subject_code'].unique()):\n",
        "  subject = []\n",
        "  subject.append(id)\n",
        "\n",
        "  subject_atc3 = []\n",
        "  subject_atc3.append(id)\n",
        "\n",
        "  subject_pd = ehr_pd[ehr_pd['subject_code'] == id]\n",
        "  subject_atc3_pd = ehr_pd[ehr_pd['subject_code'] == id]\n",
        "\n",
        "  for index, row in subject_pd.iterrows():\n",
        "    admission = []\n",
        "    admission_atc3 = []\n",
        "\n",
        "    admission.append(row['hadm_code'])\n",
        "    admission.append(row['diag_codes'])\n",
        "    admission.append(row['proc_codes'])\n",
        "    admission.append(row['med_codes'])\n",
        "\n",
        "    admission_atc3.append(row['hadm_code'])\n",
        "    admission_atc3.append(row['diag_codes'])\n",
        "    admission_atc3.append(row['proc_codes'])\n",
        "    admission_atc3.append(row['med_codes_atc3'])\n",
        "\n",
        "    subject.append(admission)\n",
        "    subject_atc3.append(admission_atc3)\n",
        "\n",
        "  records.append(subject)\n",
        "  records_atc3.append(subject_atc3)"
      ],
      "metadata": {
        "id": "P9eQeqCwSsdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(path + 'ehr_atc3.pkl', 'wb') as f:\n",
        "  pickle.dump(records_atc3, f)"
      ],
      "metadata": {
        "id": "SUctHBdzkGp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adjacency Matrices**"
      ],
      "metadata": {
        "id": "SUKZNvImFnlM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diag-Diag"
      ],
      "metadata": {
        "id": "4u223ngPF82W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diag_idx_arr = np.sort(diag_pd['icd_idx'].unique())\n",
        "diag_idx_arr_len = len(diag_idx_arr)\n",
        "\n",
        "diag_dict = {}\n",
        "diag_dict_rev = {}\n",
        "for i in range(diag_idx_arr_len):\n",
        "  diag_dict_rev[diag_idx_arr[i]] = i\n",
        "  diag_dict[i] = diag_idx_arr[i]"
      ],
      "metadata": {
        "id": "S6wWWF65BnWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnoses-Diagnoses Adj Matrix\n",
        "\n",
        "diag_adj = np.zeros((diag_idx_arr_len, diag_idx_arr_len))\n",
        "\n",
        "for subj in range(len(records)):\n",
        "  for adm in range(1, len(records[subj])):\n",
        "    diag_set = records[subj][adm][1]\n",
        "\n",
        "    if diag_set is None: break\n",
        "\n",
        "    for i, diag_i in enumerate(diag_set):\n",
        "      for j, diag_j in enumerate(diag_set):\n",
        "          if j<=i:\n",
        "            continue\n",
        "          x = diag_dict_rev[diag_i]\n",
        "          y = diag_dict_rev[diag_j]\n",
        "          diag_adj[x, y] = 1\n",
        "          diag_adj[y, x] = 1"
      ],
      "metadata": {
        "id": "xz_ZVzJr6IEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proc-Proc"
      ],
      "metadata": {
        "id": "CvKtRLWGGBbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proc_idx_arr = np.sort(proc_pd['icd_idx'].unique())\n",
        "proc_idx_arr_len = len(proc_idx_arr)\n",
        "\n",
        "proc_dict = {}\n",
        "proc_dict_rev = {}\n",
        "proc_dict_adjusted = {}\n",
        "proc_dict_rev_adjusted = {}\n",
        "for i in range(proc_idx_arr_len):\n",
        "  proc_dict_rev[proc_idx_arr[i]] = i\n",
        "  proc_dict[i] = proc_idx_arr[i]\n",
        "  proc_dict_rev_adjusted[proc_idx_arr[i]] = i+2007\n",
        "  proc_dict_adjusted[2007+i] = proc_idx_arr[i]"
      ],
      "metadata": {
        "id": "BSg15eyTDT9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Procedure-Procedure Adj Matrix\n",
        "\n",
        "proc_adj = np.zeros((proc_idx_arr_len, proc_idx_arr_len))\n",
        "\n",
        "for subj in range(len(records)):\n",
        "  for adm in range(1, len(records[subj])):\n",
        "    proc_set = records[subj][adm][2]\n",
        "\n",
        "    if proc_set is None: break\n",
        "\n",
        "    for i, proc_i in enumerate(proc_set):\n",
        "      for j, proc_j in enumerate(proc_set):\n",
        "          if j<=i:\n",
        "            continue\n",
        "          x = proc_dict_rev[proc_i]\n",
        "          y = proc_dict_rev[proc_j]\n",
        "          proc_adj[x, y] = 1\n",
        "          proc_adj[y, x] = 1"
      ],
      "metadata": {
        "id": "J8Rbi_5DEoqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proc-Diag & Diag-Proc"
      ],
      "metadata": {
        "id": "p2L63UFAGE5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Procedure & Diagnoses Adj Matrix\n",
        "diag_proc_adj = np.zeros((diag_idx_arr_len, proc_idx_arr_len))\n",
        "proc_diag_adj = np.zeros((proc_idx_arr_len, diag_idx_arr_len))\n",
        "\n",
        "for subj in range(len(records)):\n",
        "  for adm in range(1, len(records[subj])):\n",
        "    diag_set = records[subj][adm][1]\n",
        "    proc_set = records[subj][adm][2]\n",
        "\n",
        "    if proc_set is None or diag_set is None: break\n",
        "\n",
        "    for i, diag in enumerate(diag_set):\n",
        "      for j, proc in enumerate(proc_set):\n",
        "          if j<=i:\n",
        "            continue\n",
        "          x = diag_dict_rev[diag]\n",
        "          y = proc_dict_rev[proc]\n",
        "          diag_proc_adj[x, y] = 1\n",
        "          proc_diag_adj[y, x] = 1"
      ],
      "metadata": {
        "id": "gZUVxLFKFWLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Med-Med"
      ],
      "metadata": {
        "id": "y1V6OewlGHvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ATC5"
      ],
      "metadata": {
        "id": "DRWIJr0w4wFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjacency matrices for ATC Level 5 and ATC Level 3 are created."
      ],
      "metadata": {
        "id": "DR9rEVS3mfqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atc_idx_arr = np.array(list(set(list(med_pd['atc_idx'].unique()) + list(ddi_pd['atc_idx-1'].unique()) + list(ddi_pd['atc_idx-2'].unique()))))\n",
        "atc_idx_arr_len = len(atc_idx_arr)\n",
        "med_adj_map = {\n",
        "    \"atc_idx\": atc_idx_arr,\n",
        "    \"adj_idx\": np.array(range(atc_idx_arr_len))\n",
        "}\n",
        "med_adj_map_pd = pd.DataFrame(med_adj_map)\n",
        "\n",
        "atc_dict = {}\n",
        "atc_dict_rev = {}\n",
        "for i in range(atc_idx_arr_len):\n",
        "  atc_dict_rev[atc_idx_arr[i]] = i\n",
        "  atc_dict[i] = atc_idx_arr[i]"
      ],
      "metadata": {
        "id": "En06_uky7PBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjacency matrix for prescriptions\n",
        "\n",
        "prescriptions_adj = np.zeros((atc_idx_arr_len, atc_idx_arr_len))\n",
        "\n",
        "for subj in range(len(records)):\n",
        "  for adm in range(1, len(records[subj])):\n",
        "    med_set = records[subj][adm][3]\n",
        "\n",
        "    if med_set is None: break\n",
        "\n",
        "    for i, med_i in enumerate(med_set):\n",
        "      for j, med_j in enumerate(med_set):\n",
        "          if j<=i:\n",
        "            continue\n",
        "          # x = med_adj_map_pd.loc[med_adj_map_pd['atc_idx'] == med_i]['adj_idx'].item()\n",
        "          # y = med_adj_map_pd.loc[med_adj_map_pd['atc_idx'] == med_j]['adj_idx'].item()\n",
        "          x = atc_dict_rev[med_i]\n",
        "          y = atc_dict_rev[med_j]\n",
        "          prescriptions_adj[x,y] = 1\n",
        "          prescriptions_adj[y,x] = 1"
      ],
      "metadata": {
        "id": "UvpR9vOildYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjacency matrix for DDIs\n",
        "\n",
        "ddi_adj = np.zeros((atc_idx_arr_len, atc_idx_arr_len))\n",
        "\n",
        "for index, row in ddi_pd.iterrows():\n",
        "  x = atc_dict_rev[row['atc_idx-1']]\n",
        "  y = atc_dict_rev[row['atc_idx-2']]\n",
        "  ddi_adj[x, y] = 1\n",
        "  ddi_adj[y, x] = 1"
      ],
      "metadata": {
        "id": "3R5PmWbUqpWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ATC3"
      ],
      "metadata": {
        "id": "5S2tkWtK42Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atc3_idx_arr = np.array(list(set(list(med_pd_atc3['atc_idx'].unique()) + list(ddi_pd_atc3['atc_idx-1'].unique()) + list(ddi_pd_atc3['atc_idx-2'].unique()))))\n",
        "atc3_idx_arr_len = len(atc3_idx_arr)\n",
        "med_atc3_adj_map = {\n",
        "    \"atc_idx\": atc3_idx_arr,\n",
        "    \"adj_idx\": np.array(range(atc3_idx_arr_len))\n",
        "}\n",
        "med_atc3_adj_map_pd = pd.DataFrame(med_atc3_adj_map)\n",
        "\n",
        "atc3_dict = {}\n",
        "atc3_dict_rev = {}\n",
        "for i in range(atc3_idx_arr_len):\n",
        "  atc3_dict_rev[atc3_idx_arr[i]] = i\n",
        "  atc3_dict[i] = atc3_idx_arr[i]"
      ],
      "metadata": {
        "id": "rqV8HuCG44NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjacency matrix for prescriptions\n",
        "\n",
        "prescriptions_atc3_adj = np.zeros((atc3_idx_arr_len, atc3_idx_arr_len))\n",
        "\n",
        "for subj in range(len(records_atc3)):\n",
        "  for adm in range(1, len(records_atc3[subj])):\n",
        "    med_set = records_atc3[subj][adm][3]\n",
        "\n",
        "    if med_set is None: break\n",
        "\n",
        "    for i, med_i in enumerate(med_set):\n",
        "      for j, med_j in enumerate(med_set):\n",
        "          if j<=i:\n",
        "            continue\n",
        "          x = atc3_dict_rev[med_i]\n",
        "          y = atc3_dict_rev[med_j]\n",
        "          prescriptions_atc3_adj[x,y] = 1\n",
        "          prescriptions_atc3_adj[y,x] = 1"
      ],
      "metadata": {
        "id": "hF4P1WLK44NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjacency matrix for DDIs\n",
        "ddi_atc3_adj = np.zeros((atc3_idx_arr_len+1, atc3_idx_arr_len+1))\n",
        "\n",
        "for index, row in ddi_pd_atc3.iterrows():\n",
        "  x = atc3_dict_rev[row['atc_idx-1']]\n",
        "  y = atc3_dict_rev[row['atc_idx-2']]\n",
        "  ddi_atc3_adj[x, y] = 1\n",
        "  ddi_atc3_adj[y, x] = 1"
      ],
      "metadata": {
        "id": "ARAWJlH544Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Adj Matrices and Mapping Dicts"
      ],
      "metadata": {
        "id": "XD91swjUJF6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(path + 'DictMaps/diag_map_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(diag_dict, f)\n",
        "\n",
        "with open(path + 'DictMaps/diag_map_rev_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(diag_dict_rev, f)\n",
        "\n",
        "with open(path + 'DictMaps/proc_map_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(proc_dict, f)\n",
        "\n",
        "with open(path + 'DictMaps/proc_map_rev_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(proc_dict_rev, f)\n",
        "\n",
        "with open(path + 'DictMaps/proc_map_adjusted_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(proc_dict_adjusted, f)\n",
        "\n",
        "with open(path + 'DictMaps/proc_map_rev_adjusted_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(proc_dict_rev_adjusted, f)\n",
        "\n",
        "with open(path + 'DictMaps/atc_map_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(atc_dict, f)\n",
        "\n",
        "with open(path + 'DictMaps/atc_map_rev_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(atc_dict_rev, f)\n",
        "\n",
        "with open(path + 'DictMaps/atc3_map_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(atc3_dict, f)\n",
        "\n",
        "with open(path + 'DictMaps/atc3_map_rev_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(atc3_dict_rev, f)"
      ],
      "metadata": {
        "id": "5U1CGCkog98I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path + 'AdjMatrices/diag_adj.pkl', 'wb') as f:\n",
        "  pickle.dump(diag_adj, f)\n",
        "\n",
        "with open(path + 'AdjMatrices/proc_adj.pkl', 'wb') as f:\n",
        "  pickle.dump(proc_adj, f)\n",
        "\n",
        "with open(path + 'AdjMatrices/diag_proc_adj.pkl', 'wb') as f:\n",
        "  pickle.dump(diag_proc_adj, f)\n",
        "\n",
        "with open(path + 'AdjMatrices/proc_diag_adj.pkl', 'wb') as f:\n",
        "  pickle.dump(proc_diag_adj, f)\n",
        "\n",
        "with open(path + 'AdjMatrices/prescriptions_adj.pkl', 'wb') as f:\n",
        "  pickle.dump(prescriptions_adj, f)\n",
        "\n",
        "with open(path + 'AdjMatrices/ddi_adj.pkl', 'wb') as f:\n",
        "  pickle.dump(ddi_adj, f)\n",
        "\n",
        "with open(path + 'AdjMatrices/prescriptions_atc3_adj.pkl', 'wb') as f:\n",
        "  pickle.dump(prescriptions_atc3_adj, f)\n",
        "\n",
        "with open(path + 'AdjMatrices/ddi_atc3_adj.pkl', 'wb') as f:\n",
        "  pickle.dump(ddi_atc3_adj, f)"
      ],
      "metadata": {
        "id": "J7tD92yxMMhY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}